# Example found in https://github.com/python/cpython/blob/master/Lib/test/test_robotparser.py
# robots.txt for http://www.example.com/
User-agent: *
Crawl-delay: 1
Request-rate: 3/15
Disallow: /cyberworld/map/ # This is an infinite virtual URL space
# Cybermapper knows where to go.
User-agent: cybermapper
Disallow:

USER-AGENT: AwesomeBot
Crawl-delay: .7
allow: /
